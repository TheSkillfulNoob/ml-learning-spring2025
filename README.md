## COURSES TO STUDY

### 1) Stanford CS234: Reinforcement Learning
To realize the dreams and impact of AI requires autonomous systems that learn to make good decisions. Reinforcement learning is one powerful paradigm for doing so, and it is relevant to an enormous range of tasks, including robotics, game playing, consumer modeling and healthcare. This class will provide a solid introduction to the field of reinforcement learning and students will learn about the core challenges and approaches, including generalization and exploration. Through a combination of lectures, and written and coding assignments, students will become well versed in key ideas and techniques for RL. Assignments will include the basics of reinforcement learning as well as deep reinforcement learning â€” an extremely promising new area that combines deep learning techniques with reinforcement learning.

#### Prerequisites for This Class
Proficiency in Python
All class assignments will be in Python. There is a tutorial here for those who aren't as familiar with Python. If you have a lot of programming experience but in a different language (e.g. C/ C++/ Matlab/ Javascript) you will probably be fine.
College Calculus, Linear Algebra (e.g. MATH 51, CME 100)
You should be comfortable taking derivatives and understanding matrix vector operations and notation.
Basic Probability and Statistics (e.g. CS 109 or other stats course)
You should know basics of probabilities, Gaussian distributions, mean, standard deviation, etc.
Foundations of Machine Learning
We will be formulating cost functions, taking derivatives and performing optimization with gradient descent. Either CS 221 or CS 229 cover this background. Some optimization tricks will be more intuitive with some knowledge of convex optimization.

#### Learning Outcomes
Define the key features of reinforcement learning that distinguishes it from AI and non-interactive machine learning (as assessed by the exam).
Given an application problem (e.g. from computer vision, robotics, etc), decide if it should be formulated as a RL problem; if yes be able to define it formally (in terms of the state space, action space, dynamics and reward model), state what algorithm (from class) is best suited for addressing it and justify your answer (as assessed by the exam).
Implement in code common RL algorithms (as assessed by the assignments).
Describe (list and define) multiple criteria for analyzing RL algorithms and evaluate algorithms on these metrics: e.g. regret, sample complexity, computational complexity, empirical performance, convergence, etc (as assessed by assignments and the exam).
Describe the exploration vs exploitation challenge and compare and contrast at least two approaches for addressing this challenge (in terms of performance, scalability, complexity of implementation, and theoretical guarantees) (as assessed by an assignment and the exam).

[text](https://web.stanford.edu/class/cs234/CS234Spr2024/CS234Win2023/modules.html)

### 2) MIT CSE 691: TOPICS IN REINFORCEMENT LEARNING
This course will focus on Reinforcement Learning (RL), a currently very active sub eld of arti cial intelligence. It will discuss selectively a number of algorithmic topics, such as approximation in value and policy space, approximate policy iteration, rollout (a one-time form of policy iteration), model predictive control, large language models, multiagent methods, and their applications to challenging engineering, operations research, and computer science problems. 

#### Learning Outcome: Methods
On the methodological side, our course will be couched on a conceptual framework that centers around two algorithms, which are designed largely independently of each other and operate in synergy through the powerful mechanism of the classical Newton s method. We call these the o-line training and the on-line play algorithms; the names are borrowed from some of the major successes of RL involving games, such as AlphaZero and TD-Gammon. These algorithms can be implemented in many different ways, and we will emphasize approximate versions of classical Dynamic Programming (DP) algorithms such as value iteration, policy iteration, and rollout. 

#### Learning Outcome: Application
On the application side, our course will illustrate the RL and approximate DP methodologies within a broad variety of settings involving model predictive and adaptive control, robotics and autonomous systems, large language models, data association, health care, cybersecurity, network infrastructures, and two-person games. The primary emphasis of the course is to encourage graduate student research in reinforcement learning through directed reading and interactions with the instructors. Prerequisites are a full course on calculus and background in probability.

#### Learning Topics
Algorithmic Topics: (1) Introduction to exact and approximate dynamic programming (2) Approximation in value and policy space (3) O-line training, on-line play, and Newtons method (4) Rollout and approximate policy iteration (5) Model predictive and adaptive control (6) Multiagent reinforcement learning (7) Discrete optimization using rollout (8) Sequential estimation and Bayesian optimization (9) Training of feature-based approximation architectures and neural networks Application Topics: (1) Robotics and autonomous systems in multiagent environments (2) Large language models (3) Inference and optimization of Hidden Markov Models (4) Data association (5) Two-person games and computer chess (6) Infrastructure networks and supply chains (7) Cybersecurity applications (8) Health care

[text](http://web.mit.edu/dimitrib/www/RLbook.html)